{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu6n99zoBT5AqmRsL45V6k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saakshi05/ML-projects/blob/main/growthlinkml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Customer Churn Prediction"
      ],
      "metadata": {
        "id": "jMsop5AwTdKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "6ulKJ84ATeGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "file_path = \"Churn_Modelling.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "9oWS0bVVTeI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display initial data info\n",
        "df_info = df.info()\n",
        "df_head = df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9b9MWFMWo26",
        "outputId": "51490526-0c29-4c54-9c9a-a1d7b9d594ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 11 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   CreditScore      10000 non-null  int64  \n",
            " 1   Geography        10000 non-null  int64  \n",
            " 2   Gender           10000 non-null  int64  \n",
            " 3   Age              10000 non-null  int64  \n",
            " 4   Tenure           10000 non-null  int64  \n",
            " 5   Balance          10000 non-null  float64\n",
            " 6   NumOfProducts    10000 non-null  int64  \n",
            " 7   HasCrCard        10000 non-null  int64  \n",
            " 8   IsActiveMember   10000 non-null  int64  \n",
            " 9   EstimatedSalary  10000 non-null  float64\n",
            " 10  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9)\n",
            "memory usage: 859.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()"
      ],
      "metadata": {
        "id": "W_VZP56cXAdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop irrelevant columns\n",
        "df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "RDGibKANTeMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables\n",
        "df[\"Geography\"] = LabelEncoder().fit_transform(df[\"Geography\"])\n",
        "df[\"Gender\"] = LabelEncoder().fit_transform(df[\"Gender\"])"
      ],
      "metadata": {
        "id": "epKUpxF_TePF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and target variable\n",
        "X = df.drop(\"Exited\", axis=1)\n",
        "y = df[\"Exited\"]"
      ],
      "metadata": {
        "id": "ZYz4z6orTeSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "9eF1hXFHTeU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "vXYvaFpyTeX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "MEBieXjvTeae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store results\n",
        "results = {}\n",
        "feature_importances = {}"
      ],
      "metadata": {
        "id": "X7sc94GXTede"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\"Accuracy\": accuracy, \"Confusion Matrix\": conf_matrix, \"Report\": class_report}\n",
        "\n",
        "    # Extract feature importance for Random Forest and XGBoost\n",
        "    if name in [\"Random Forest\", \"XGBoost\"]:\n",
        "        feature_importances[name] = model.feature_importances_"
      ],
      "metadata": {
        "id": "3Y61SbscTegl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert feature importance to DataFrame for visualization\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Random Forest Importance\": feature_importances[\"Random Forest\"],\n",
        "    \"XGBoost Importance\": feature_importances[\"XGBoost\"],\n",
        "})"
      ],
      "metadata": {
        "id": "Dj8iElVvTerV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Dataset Information\n",
        "print(\"\\n===== Dataset Information =====\")\n",
        "print(df_info)\n",
        "\n",
        "# Print First Few Rows of the Dataset\n",
        "print(\"\\n===== First 5 Rows of the Dataset =====\")\n",
        "print(df_head)\n",
        "\n",
        "# Print Missing Values (if any)\n",
        "print(\"\\n===== Missing Values in Dataset =====\")\n",
        "print(missing_values)\n",
        "\n",
        "# Print Model Performance Metrics\n",
        "print(\"\\n===== Model Performance =====\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"\\n--- {model_name} ---\")\n",
        "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(metrics[\"Confusion Matrix\"])\n",
        "    print(\"Classification Report:\")\n",
        "    print(metrics[\"Report\"])\n",
        "\n",
        "# Print Feature Importance Analysis\n",
        "print(\"\\n===== Feature Importance (Top Factors Influencing Churn) =====\")\n",
        "print(feature_importance_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PvvIZfCV7xj",
        "outputId": "86a05945-cbfc-4558-988f-f7115dac629f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Dataset Information =====\n",
            "None\n",
            "\n",
            "===== First 5 Rows of the Dataset =====\n",
            "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
            "0          619          0       0   42       2       0.00              1   \n",
            "1          608          2       0   41       1   83807.86              1   \n",
            "2          502          0       0   42       8  159660.80              3   \n",
            "3          699          0       0   39       1       0.00              2   \n",
            "4          850          2       0   43       2  125510.82              1   \n",
            "\n",
            "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
            "0          1               1        101348.88       1  \n",
            "1          0               1        112542.58       0  \n",
            "2          1               0        113931.57       1  \n",
            "3          0               0         93826.63       0  \n",
            "4          1               1         79084.10       0  \n",
            "\n",
            "===== Missing Values in Dataset =====\n",
            "CreditScore        0\n",
            "Geography          0\n",
            "Gender             0\n",
            "Age                0\n",
            "Tenure             0\n",
            "Balance            0\n",
            "NumOfProducts      0\n",
            "HasCrCard          0\n",
            "IsActiveMember     0\n",
            "EstimatedSalary    0\n",
            "Exited             0\n",
            "dtype: int64\n",
            "\n",
            "===== Model Performance =====\n",
            "\n",
            "--- Random Forest ---\n",
            "Accuracy: 0.8645\n",
            "Confusion Matrix:\n",
            "[[1542   51]\n",
            " [ 220  187]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92      1593\n",
            "           1       0.79      0.46      0.58       407\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.83      0.71      0.75      2000\n",
            "weighted avg       0.86      0.86      0.85      2000\n",
            "\n",
            "\n",
            "--- Logistic Regression ---\n",
            "Accuracy: 0.8050\n",
            "Confusion Matrix:\n",
            "[[1552   41]\n",
            " [ 349   58]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89      1593\n",
            "           1       0.59      0.14      0.23       407\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.70      0.56      0.56      2000\n",
            "weighted avg       0.77      0.81      0.75      2000\n",
            "\n",
            "\n",
            "--- XGBoost ---\n",
            "Accuracy: 0.8470\n",
            "Confusion Matrix:\n",
            "[[1506   87]\n",
            " [ 219  188]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91      1593\n",
            "           1       0.68      0.46      0.55       407\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.78      0.70      0.73      2000\n",
            "weighted avg       0.83      0.85      0.84      2000\n",
            "\n",
            "\n",
            "===== Feature Importance (Top Factors Influencing Churn) =====\n",
            "        Feature  Random Forest Importance  XGBoost Importance\n",
            "  NumOfProducts                  0.129134            0.323487\n",
            " IsActiveMember                  0.039596            0.190994\n",
            "            Age                  0.239934            0.134641\n",
            "      Geography                  0.038467            0.077780\n",
            "        Balance                  0.141194            0.062662\n",
            "         Gender                  0.018959            0.050827\n",
            "EstimatedSalary                  0.147069            0.042242\n",
            "    CreditScore                  0.144104            0.042049\n",
            "         Tenure                  0.081958            0.039592\n",
            "      HasCrCard                  0.019583            0.035726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: Spam SMS Detection"
      ],
      "metadata": {
        "id": "xIoVHr5iYQi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "file_path = 'spam.csv'\n",
        "df = pd.read_csv(file_path, encoding='latin-1')\n",
        "\n",
        "# Data cleaning: Keep only necessary columns\n",
        "df = df.iloc[:, :2]\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})  # Convert labels to binary\n",
        "\n",
        "# Drop any rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Remove punctuation\n",
        "        text = re.sub(\"\\\\d+\", \"\", text)  # Remove numbers\n",
        "        text = re.sub(\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "df['cleaned_message'] = df['message'].apply(clean_text)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_message'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "# Ensure no NaN values in target variable\n",
        "y_train = y_train.dropna()\n",
        "y_test = y_test.dropna()\n",
        "\n",
        "# Text vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "print(\"\\nA robust model that accurately distinguishes between spam and legitimate messages, with well-documented preprocessing and classification approaches.\\n\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "FfPbwHJxV8FS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb94f7ff-0f35-4288-90c7-f12cc5d7788f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A robust model that accurately distinguishes between spam and legitimate messages, with well-documented preprocessing and classification approaches.\n",
            "\n",
            "\n",
            "Naive Bayes Performance:\n",
            "Accuracy: 0.9623318385650225\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       966\n",
            "           1       0.99      0.72      0.84       149\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.98      0.86      0.91      1115\n",
            "weighted avg       0.96      0.96      0.96      1115\n",
            "\n",
            "\n",
            "Logistic Regression Performance:\n",
            "Accuracy: 0.9605381165919282\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       966\n",
            "           1       0.99      0.71      0.83       149\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.97      0.86      0.90      1115\n",
            "weighted avg       0.96      0.96      0.96      1115\n",
            "\n",
            "\n",
            "Random Forest Performance:\n",
            "Accuracy: 0.9739910313901345\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       966\n",
            "           1       1.00      0.81      0.89       149\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.99      0.90      0.94      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}